{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51b0434d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import snappy\n",
    "from os.path import join\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import jpy\n",
    "System = jpy.get_type('java.lang.System')\n",
    "System.gc()\n",
    "import gc\n",
    "\n",
    "import re\n",
    "from geomet import wkt\n",
    "from snappy import GPF\n",
    "from snappy import ProductIO\n",
    "from snappy import HashMap\n",
    "from snappy import jpy\n",
    "HashMap = snappy.jpy.get_type('java.util.HashMap')\n",
    "import time\n",
    "import evros\n",
    "import configparser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b1326e",
   "metadata": {},
   "source": [
    "<h1> Read the Location Where the Sentinels are Stored </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1828892e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the ini file\n",
    "config = configparser.ConfigParser()\n",
    "config.read('sentinels.ini')\n",
    "path = config['SENTINELS']['path']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47f35e0",
   "metadata": {},
   "source": [
    "<h1> Sentinel 2 </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33700289",
   "metadata": {},
   "source": [
    "# Read Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e171d2c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Process_Level</th>\n",
       "      <th>Sensing_Date</th>\n",
       "      <th>Relevant_Orbit</th>\n",
       "      <th>Height</th>\n",
       "      <th>Width</th>\n",
       "      <th>Band_Names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S2A_MSIL2A_20200111T091341_N9999_R050_T35TMF_2...</td>\n",
       "      <td>MSIL2A</td>\n",
       "      <td>20200111T091341</td>\n",
       "      <td>R050</td>\n",
       "      <td>10980</td>\n",
       "      <td>10980</td>\n",
       "      <td>[B1, B2, B3, B4, B5, B6, B7, B8, B8A, B9, B11,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S2A_MSIL2A_20200417T085601_N9999_R007_T35TMF_2...</td>\n",
       "      <td>MSIL2A</td>\n",
       "      <td>20200417T085601</td>\n",
       "      <td>R007</td>\n",
       "      <td>10980</td>\n",
       "      <td>10980</td>\n",
       "      <td>[B1, B2, B3, B4, B5, B6, B7, B8, B8A, B9, B11,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S2A_MSIL2A_20200716T085601_N0214_R007_T35TMF_2...</td>\n",
       "      <td>MSIL2A</td>\n",
       "      <td>20200716T085601</td>\n",
       "      <td>R007</td>\n",
       "      <td>10980</td>\n",
       "      <td>10980</td>\n",
       "      <td>[B1, B2, B3, B4, B5, B6, B7, B8, B8A, B9, B11,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S2A_MSIL2A_20201024T090041_N0214_R007_T35TMF_2...</td>\n",
       "      <td>MSIL2A</td>\n",
       "      <td>20201024T090041</td>\n",
       "      <td>R007</td>\n",
       "      <td>10980</td>\n",
       "      <td>10980</td>\n",
       "      <td>[B1, B2, B3, B4, B5, B6, B7, B8, B8A, B9, B11,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Name Process_Level  \\\n",
       "0  S2A_MSIL2A_20200111T091341_N9999_R050_T35TMF_2...        MSIL2A   \n",
       "1  S2A_MSIL2A_20200417T085601_N9999_R007_T35TMF_2...        MSIL2A   \n",
       "2  S2A_MSIL2A_20200716T085601_N0214_R007_T35TMF_2...        MSIL2A   \n",
       "3  S2A_MSIL2A_20201024T090041_N0214_R007_T35TMF_2...        MSIL2A   \n",
       "\n",
       "      Sensing_Date Relevant_Orbit  Height  Width  \\\n",
       "0  20200111T091341           R050   10980  10980   \n",
       "1  20200417T085601           R007   10980  10980   \n",
       "2  20200716T085601           R007   10980  10980   \n",
       "3  20201024T090041           R007   10980  10980   \n",
       "\n",
       "                                          Band_Names  \n",
       "0  [B1, B2, B3, B4, B5, B6, B7, B8, B8A, B9, B11,...  \n",
       "1  [B1, B2, B3, B4, B5, B6, B7, B8, B8A, B9, B11,...  \n",
       "2  [B1, B2, B3, B4, B5, B6, B7, B8, B8A, B9, B11,...  \n",
       "3  [B1, B2, B3, B4, B5, B6, B7, B8, B8A, B9, B11,...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set target folder and extract metadata - Change accordingly \n",
    "# product_path = str('D://EVROS//Satellite_Images//Copernicus_2016_2020//CODE//Sample_Data//raw/Sentinel2/')\n",
    "\n",
    "product_path = str(path)+str('raw/Sentinel2/')\n",
    "\n",
    "input_S2_files = sorted(os.listdir(product_path))\n",
    "\n",
    "name, process_level, sensing_date, relevant_orbit, height, width, band_names = ([] for i in range(7))\n",
    "\n",
    "for i in input_S2_files:\n",
    "    process_level.append(i.split(\"_\")[1])\n",
    "    sensing_date.append(i.split(\"_\")[2])\n",
    "    relevant_orbit.append(i.split(\"_\")[4])\n",
    "    # Read with snappy\n",
    "    s2_read = snappy.ProductIO.readProduct(product_path + i)\n",
    "    name.append(s2_read.getName())\n",
    "    height.append(s2_read.getSceneRasterHeight())\n",
    "    width.append(s2_read.getSceneRasterWidth())\n",
    "    band_names.append(s2_read.getBandNames())\n",
    "    \n",
    "df_s2_read = pd.DataFrame({'Name': name, 'Process_Level': process_level, 'Sensing_Date': sensing_date, 'Relevant_Orbit': relevant_orbit, 'Height': height, 'Width': width, 'Band_Names': band_names})\n",
    "display(df_s2_read)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3f357b",
   "metadata": {},
   "source": [
    "<h1> Produce Classification Maps from Sentinel 2 </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8edb21ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading S2A_MSIL2A_20200111T091341_N9999_R050_T35TMF_20210628T075932\n",
      "\n",
      "Subseting the product....\n",
      "Resampling the product....\n",
      "Applying PCA.....\n",
      "Calculating NDVI and mNDWI....\n",
      "Stacking the images....\n",
      "Implementing Kmeans....\n",
      "Saving the new product on disk...\n",
      "\n",
      "\n",
      "Reading S2A_MSIL2A_20200417T085601_N9999_R007_T35TMF_20210628T081551\n",
      "\n",
      "Subseting the product....\n",
      "Resampling the product....\n",
      "Applying PCA.....\n",
      "Calculating NDVI and mNDWI....\n",
      "Stacking the images....\n",
      "Implementing Kmeans....\n",
      "Saving the new product on disk...\n",
      "\n",
      "\n",
      "Reading S2A_MSIL2A_20200716T085601_N0214_R007_T35TMF_20200716T120405\n",
      "\n",
      "Subseting the product....\n",
      "Resampling the product....\n",
      "Applying PCA.....\n",
      "Calculating NDVI and mNDWI....\n",
      "Stacking the images....\n",
      "Implementing Kmeans....\n",
      "Saving the new product on disk...\n",
      "\n",
      "\n",
      "Reading S2A_MSIL2A_20201024T090041_N0214_R007_T35TMF_20201024T114948\n",
      "\n",
      "Subseting the product....\n",
      "Resampling the product....\n",
      "Applying PCA.....\n",
      "Calculating NDVI and mNDWI....\n",
      "Stacking the images....\n",
      "Implementing Kmeans....\n",
      "Saving the new product on disk...\n",
      "\n",
      "\n",
      "Calculating Classification Maps from Sentinel 2 Images has Finished\n"
     ]
    }
   ],
   "source": [
    "# outpath_name = 'D://EVROS//Satellite_Images//Copernicus_2016_2020//CODE//Sample_Data/classification_maps/'\n",
    "\n",
    "outpath_name = str(path)+str('classification_maps/')\n",
    "\n",
    "if not(os.path.exists(outpath_name) and os.path.isdir(outpath_name)):\n",
    "    os.makedirs(outpath_name)\n",
    "\n",
    "for i in input_S2_files:\n",
    "    \n",
    "    s2_read = snappy.ProductIO.readProduct(product_path + i)                   \n",
    "    name = s2_read.getName()\n",
    "    print(f'Reading {name}\\n')\n",
    "    output = str(outpath_name) + str(name)\n",
    "    \n",
    "    # subset the product\n",
    "    subset_prod = evros.subset_s2(s2_read)                                           \n",
    "\n",
    "    # resample the product to 10m spatial resolution\n",
    "    resampled = evros.resample_s2(subset_prod)                                       \n",
    "     \n",
    "    # calculate the first principal component\n",
    "    component_1 = evros.pca_s2(resampled)\n",
    "    \n",
    "    # calculate the NDVI and mNDVI\n",
    "    ndvi, ndwi = evros.ndvi_ndwi(resampled)\n",
    "    \n",
    "    # stack the pca , ndvi and mndvi into a single product\n",
    "    stacked = evros.stack(component_1, ndvi, ndwi)\n",
    "    \n",
    "    # implement Kmeans unsupervised classification\n",
    "    classification_map = evros.kmeans_s2(stacked)\n",
    "    \n",
    "    \n",
    "    # Wite the classification map on the local disk\n",
    "    snappy.ProductIO.writeProduct(classification_map , output+\"_cluster\", 'GeoTIFF')  # save the new product on disk\n",
    "    print(f'Saving the new product on disk...')\n",
    "    \n",
    "    del s2_read, subset_prod, resampled, component_1, ndvi, ndwi, stacked\n",
    "    gc.collect()\n",
    "    print('\\n')\n",
    "    \n",
    "print('Calculating Classification Maps from Sentinel 2 Images has Finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cae8b3",
   "metadata": {},
   "source": [
    "<h1> Sentinel 1 </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63b9afa",
   "metadata": {},
   "source": [
    "<h1> Read Products </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57815f23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Process_Level</th>\n",
       "      <th>Sensing_Date</th>\n",
       "      <th>Relevant_Orbit</th>\n",
       "      <th>Height</th>\n",
       "      <th>Width</th>\n",
       "      <th>Band_Names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S1A_IW_GRDH_1SDV_20200115T042244_20200115T0423...</td>\n",
       "      <td>IW</td>\n",
       "      <td>GRDH</td>\n",
       "      <td>20200115T042244</td>\n",
       "      <td>16691</td>\n",
       "      <td>25972</td>\n",
       "      <td>[Amplitude_VH, Intensity_VH, Amplitude_VV, Int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S1A_IW_GRDH_1SDV_20200414T161600_20200414T1616...</td>\n",
       "      <td>IW</td>\n",
       "      <td>GRDH</td>\n",
       "      <td>20200414T161600</td>\n",
       "      <td>16671</td>\n",
       "      <td>26450</td>\n",
       "      <td>[Amplitude_VH, Intensity_VH, Amplitude_VV, Int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S1A_IW_GRDH_1SDV_20200713T042249_20200713T0423...</td>\n",
       "      <td>IW</td>\n",
       "      <td>GRDH</td>\n",
       "      <td>20200713T042249</td>\n",
       "      <td>16691</td>\n",
       "      <td>25967</td>\n",
       "      <td>[Amplitude_VH, Intensity_VH, Amplitude_VV, Int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S1A_IW_GRDH_1SDV_20201017T042253_20201017T0423...</td>\n",
       "      <td>IW</td>\n",
       "      <td>GRDH</td>\n",
       "      <td>20201017T042253</td>\n",
       "      <td>16691</td>\n",
       "      <td>25972</td>\n",
       "      <td>[Amplitude_VH, Intensity_VH, Amplitude_VV, Int...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Name Process_Level  \\\n",
       "0  S1A_IW_GRDH_1SDV_20200115T042244_20200115T0423...            IW   \n",
       "1  S1A_IW_GRDH_1SDV_20200414T161600_20200414T1616...            IW   \n",
       "2  S1A_IW_GRDH_1SDV_20200713T042249_20200713T0423...            IW   \n",
       "3  S1A_IW_GRDH_1SDV_20201017T042253_20201017T0423...            IW   \n",
       "\n",
       "  Sensing_Date   Relevant_Orbit  Height  Width  \\\n",
       "0         GRDH  20200115T042244   16691  25972   \n",
       "1         GRDH  20200414T161600   16671  26450   \n",
       "2         GRDH  20200713T042249   16691  25967   \n",
       "3         GRDH  20201017T042253   16691  25972   \n",
       "\n",
       "                                          Band_Names  \n",
       "0  [Amplitude_VH, Intensity_VH, Amplitude_VV, Int...  \n",
       "1  [Amplitude_VH, Intensity_VH, Amplitude_VV, Int...  \n",
       "2  [Amplitude_VH, Intensity_VH, Amplitude_VV, Int...  \n",
       "3  [Amplitude_VH, Intensity_VH, Amplitude_VV, Int...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set target folder and extract metadata - Change accordingly\n",
    "# product_path = str('D://EVROS//Satellite_Images//Copernicus_2016_2020//CODE//Sample_Data//raw/Sentinel1/')\n",
    "product_path = str(path)+str('raw/Sentinel1/')\n",
    "\n",
    "input_S1_files = sorted(os.listdir(product_path))\n",
    "\n",
    "name, process_level, sensing_date, relevant_orbit, height, width, band_names = ([] for i in range(7))\n",
    "\n",
    "\n",
    "for i in input_S1_files:\n",
    "    process_level.append(i.split(\"_\")[1])\n",
    "    sensing_date.append(i.split(\"_\")[2])\n",
    "    relevant_orbit.append(i.split(\"_\")[4])\n",
    "    # Read with snappy\n",
    "    s1_read = snappy.ProductIO.readProduct(product_path + i)\n",
    "    name.append(s1_read.getName())\n",
    "    height.append(s1_read.getSceneRasterHeight())\n",
    "    width.append(s1_read.getSceneRasterWidth())\n",
    "    band_names.append(s1_read.getBandNames())\n",
    "    \n",
    "df_s1_read = pd.DataFrame({'Name': name, 'Process_Level': process_level, 'Sensing_Date': sensing_date, 'Relevant_Orbit': relevant_orbit, 'Height': height, 'Width': width, 'Band_Names': band_names})\n",
    "display(df_s1_read)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050cd063",
   "metadata": {},
   "source": [
    "<h1> Produce Classification Maps using Sentinel 1 </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0cdc83e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading product S1A_IW_GRDH_1SDV_20200115T042244_20200115T042309_030806_0388A1_15AA\n",
      "Orbit updated succesfully\n",
      "Calibration implemented succesfully\n",
      "Speckle Filtering applied succesfully\n",
      "Applying Linear to dB...\n",
      "Terrain Correction and Reprojection applied successfully\n",
      "Subset implemented succesfully\n",
      "Sigma0_VH_db,Sigma0_VV_db\n",
      "Applying K-means has finished\n",
      "Saving the new product on disk...\n",
      "\n",
      "\n",
      "Reading product S1A_IW_GRDH_1SDV_20200414T161600_20200414T161625_032126_03B6B8_3C7F\n",
      "Orbit updated succesfully\n",
      "Calibration implemented succesfully\n",
      "Speckle Filtering applied succesfully\n",
      "Applying Linear to dB...\n",
      "Terrain Correction and Reprojection applied successfully\n",
      "Subset implemented succesfully\n",
      "Sigma0_VH_db,Sigma0_VV_db\n",
      "Applying K-means has finished\n",
      "Saving the new product on disk...\n",
      "\n",
      "\n",
      "Reading product S1A_IW_GRDH_1SDV_20200713T042249_20200713T042314_033431_03DFB3_BC6C\n",
      "Orbit updated succesfully\n",
      "Calibration implemented succesfully\n",
      "Speckle Filtering applied succesfully\n",
      "Applying Linear to dB...\n",
      "Terrain Correction and Reprojection applied successfully\n",
      "Subset implemented succesfully\n",
      "Sigma0_VH_db,Sigma0_VV_db\n",
      "Applying K-means has finished\n",
      "Saving the new product on disk...\n",
      "\n",
      "\n",
      "Reading product S1A_IW_GRDH_1SDV_20201017T042253_20201017T042318_034831_040F61_EB8E\n",
      "Orbit updated succesfully\n",
      "Calibration implemented succesfully\n",
      "Speckle Filtering applied succesfully\n",
      "Applying Linear to dB...\n",
      "Terrain Correction and Reprojection applied successfully\n",
      "Subset implemented succesfully\n",
      "Sigma0_VH_db,Sigma0_VV_db\n",
      "Applying K-means has finished\n",
      "Saving the new product on disk...\n",
      "\n",
      "\n",
      "Calculating Classification Maps from Sentinel 1 products has finished!\n"
     ]
    }
   ],
   "source": [
    "outpath_name = str(path)+str('classification_maps/')\n",
    "\n",
    "if not(os.path.exists(outpath_name) and os.path.isdir(outpath_name)):\n",
    "    os.makedirs(outpath_name)\n",
    "\n",
    "for i in input_S1_files:\n",
    "    \n",
    "    s1_read = snappy.ProductIO.readProduct(product_path + i)                   # read the product\n",
    "    name = s1_read.getName()\n",
    "    output = str(outpath_name) + str(name)\n",
    "    print(f'Reading product {name}\\n')\n",
    "    \n",
    "    # Apply orbit file\n",
    "    appply_orbit = evros.applyorbitfile(s1_read)\n",
    "    \n",
    "    # Callibration\n",
    "    calibration = evros.s1_calibration(appply_orbit)\n",
    "    \n",
    "    # Speckle Filtering\n",
    "    speckle = evros.specklefilter(calibration)\n",
    "    \n",
    "    # Linear to dB\n",
    "    db = evros.lineartodB(speckle)\n",
    "    \n",
    "    # Terrain Correction\n",
    "    terrain = evros.terrain_correction(db)\n",
    "    \n",
    "    # Apply resampling\n",
    "#     resampled = evros.resample_s1(terrain)\n",
    "    \n",
    "    # Subset\n",
    "    subset = evros.subset_s1(terrain)\n",
    "    \n",
    "    # Applying Kmeans\n",
    "    cluster = evros.kmeans_s1(subset)\n",
    "    \n",
    "    \n",
    "    # Saving the product on local disk\n",
    "    snappy.ProductIO.writeProduct(cluster , output+\"_cluster\", 'GeoTIFF')  \n",
    "    print(f'Saving the new product on disk...')\n",
    "    \n",
    "    del s1_read, appply_orbit, calibration, speckle, terrain, subset\n",
    "    gc.collect()\n",
    "    print('\\n')\n",
    "    \n",
    "print('Calculating Classification Maps from Sentinel 1 products has finished!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d7de8a",
   "metadata": {},
   "source": [
    "<h1> Align Classification Maps </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8c51d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from osgeo import gdal\n",
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "from gdal import gdalconst\n",
    "os.chdir(str(path)+str('classification_maps/')) # Change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3fab0fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The master image is S1A_IW_GRDH_1SDV_20200115T042244_20200115T042309_030806_0388A1_15AA_cluster.tif\n",
      "\n",
      "S1A_IW_GRDH_1SDV_20200414T161600_20200414T161625_032126_03B6B8_3C7F_cluster.tif\n",
      "S1A_IW_GRDH_1SDV_20200713T042249_20200713T042314_033431_03DFB3_BC6C_cluster.tif\n",
      "S1A_IW_GRDH_1SDV_20201017T042253_20201017T042318_034831_040F61_EB8E_cluster.tif\n",
      "S2A_MSIL2A_20200111T091341_N9999_R050_T35TMF_20210628T075932_cluster.tif\n",
      "S2A_MSIL2A_20200417T085601_N9999_R007_T35TMF_20210628T081551_cluster.tif\n",
      "S2A_MSIL2A_20200716T085601_N0214_R007_T35TMF_20200716T120405_cluster.tif\n",
      "S2A_MSIL2A_20201024T090041_N0214_R007_T35TMF_20201024T114948_cluster.tif\n",
      "Aligning Images has Finished!\n"
     ]
    }
   ],
   "source": [
    "# Create a list of all available sentinel 1 images\n",
    "listofimages = []\n",
    "listofimages = glob('*.tif')\n",
    "\n",
    "print(f'The master image is {listofimages[0]}\\n')\n",
    "\n",
    "for image in listofimages[1:]:\n",
    "    print(image) # print the name of the product to be aligned \n",
    "    \n",
    "    # Slave Product\n",
    "    inputimage = gdal.Open(image, gdalconst.GA_ReadOnly)\n",
    "    inputProj = inputimage.GetProjection()\n",
    "\n",
    "    #Master product - All images will be aligned with this one\n",
    "    reference = gdal.Open(listofimages[0], gdalconst.GA_ReadOnly)\n",
    "    referenceProj = reference.GetProjection()\n",
    "    referenceTrans = reference.GetGeoTransform()\n",
    "    x = reference.RasterXSize\n",
    "    y = reference.RasterYSize\n",
    "\n",
    "    driver= gdal.GetDriverByName('GTiff')\n",
    "    output = driver.Create(str(image[:-4])+str('_aligned.tif'), x, y, 2, gdal.GDT_Float32)\n",
    "    output.SetGeoTransform(referenceTrans)\n",
    "    output.SetProjection(referenceProj)\n",
    "    dstband= output.GetRasterBand(1)\n",
    "    dstband.SetNoDataValue(np.nan)\n",
    "    gdal.ReprojectImage(inputimage, output, inputProj, referenceProj, gdalconst.GRA_Med)\n",
    "    dstband.FlushCache()\n",
    "    output.FlushCache()\n",
    "\n",
    "    inputimage = None\n",
    "    reference = None\n",
    "    dstband = None\n",
    "    output = None\n",
    "    \n",
    "print('Aligning Images has Finished!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773c4f61",
   "metadata": {},
   "source": [
    "<h1> Create the Final Probability Map </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "131034d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Costructing Classification map....\n",
      "\n",
      "Calculating the Final Probability Map has Finished!!\n"
     ]
    }
   ],
   "source": [
    "# The name of the folder where the probability map will be stored.\n",
    "# outputPath = 'D://EVROS//Satellite_Images//Copernicus_2016_2020//CODE//Sample_Data/probability_maps/'\n",
    "\n",
    "outputPath = str(path)+str('probability_maps/')\n",
    "if not(os.path.exists(outputPath) and os.path.isdir(outputPath)):\n",
    "    os.makedirs(outputPath)\n",
    "    \n",
    "    \n",
    "listofclusters = []\n",
    "listofclusters = glob('S**_aligned.tif')\n",
    "\n",
    "\n",
    "##########################  ############################\n",
    "# Get array image dimensions, projection, transform\n",
    "im = gdal.Open(listofclusters[0])\n",
    "Y = im.RasterYSize\n",
    "X = im.RasterXSize\n",
    "proj = im.GetProjection()\n",
    "transf = im.GetGeoTransform()\n",
    "im = None\n",
    "\n",
    "##############  stack classification maps from previous step\n",
    "print('Costructing Classification map....\\n')\n",
    "stack = np.empty((X*Y, len(listofclusters)))\n",
    "c = 0\n",
    "for i in listofclusters:\n",
    "    im = gdal.Open(i)\n",
    "    img = im.GetRasterBand(1).ReadAsArray()\n",
    "    stack[:, c] = img.flatten()\n",
    "    c += 1\n",
    "# # Replace value 0 (clouds) with NaN    \n",
    "stack[stack >1 ] = np.nan\n",
    "\n",
    "# mean\n",
    "meanm = np.nanmean(stack,1)\n",
    "stack = None\n",
    "# Export Map\n",
    "out_dat = meanm.reshape((Y, X))\n",
    "driverTiff = gdal.GetDriverByName('GTiff')\n",
    "out = driverTiff.Create(outputPath+'Mean_Map_Final.tif', X, Y, 1, gdal.GDT_Float32)\n",
    "out.SetGeoTransform(transf)\n",
    "out.SetProjection(proj)\n",
    "out.GetRasterBand(1).WriteArray(out_dat)\n",
    "out = None\n",
    "\n",
    "print('Calculating the Final Probability Map has Finished!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0764bb41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a186c4db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce57119",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
